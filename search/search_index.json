{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"LSFB Dataset Companion Library LSFB Dataset is a companion library for the French Belgian Sign Language (LSFB) dataset released by the University of Namur. The library provides a set of tools helping to load the dataset in python data structures or to visualize the data. This library reduce drastically the time you will spend on data loading and preprocessing allowing you to focus on your research. Datasets Both datasets are based on the LSFB Corpus . The corpus is the result of the a tremendous work achieved by the members of the LSFB labl from the university of Namur. The corpus data were sanatized in order to make them easier to use. Additional metadata were added to enhance the datasets. Two versions of the dataset are available: LSFB Isol : Suitable for the isolated sign language recognition task. LSFB Cont : Suitable for the continuous sign language recognition task. Modules This library offers a set of modules designed to help you manipulating the datasets with minimal effort. The modules are: datasets : contains pre-written Pytorch Dataset classes that can be used to load and feed directly the data into a Pytorch model. transforms : contains transforms designed to apply various pre-processing to the videos. visualisation : contains helper function enabling you to visualise the data. utils : contains function helping to load the various csv and video into dataframes Sponsors Without our sponsors, this library would not be possible.","title":"Home"},{"location":"#lsfb-dataset-companion-library","text":"LSFB Dataset is a companion library for the French Belgian Sign Language (LSFB) dataset released by the University of Namur. The library provides a set of tools helping to load the dataset in python data structures or to visualize the data. This library reduce drastically the time you will spend on data loading and preprocessing allowing you to focus on your research.","title":"LSFB Dataset Companion Library"},{"location":"#datasets","text":"Both datasets are based on the LSFB Corpus . The corpus is the result of the a tremendous work achieved by the members of the LSFB labl from the university of Namur. The corpus data were sanatized in order to make them easier to use. Additional metadata were added to enhance the datasets. Two versions of the dataset are available: LSFB Isol : Suitable for the isolated sign language recognition task. LSFB Cont : Suitable for the continuous sign language recognition task.","title":"Datasets"},{"location":"#modules","text":"This library offers a set of modules designed to help you manipulating the datasets with minimal effort. The modules are: datasets : contains pre-written Pytorch Dataset classes that can be used to load and feed directly the data into a Pytorch model. transforms : contains transforms designed to apply various pre-processing to the videos. visualisation : contains helper function enabling you to visualise the data. utils : contains function helping to load the various csv and video into dataframes","title":"Modules"},{"location":"#sponsors","text":"Without our sponsors, this library would not be possible.","title":"Sponsors"},{"location":"download/","text":"Download Datasets To ease the download of the datasets, we provide a python script that will download the datasets for you. The script is desined to download the dataset in an incremental way. Thus, no worries if you stop the download midway. The script will resume the download where it left off. It is also able to update the dataset if new videos or feature are added. Basic Usage Here is a simple snippet of code to download the isolated version of the dataset : from lsfb_dataset.utils.download.dataset_downloader import DatasetDownloader destination_folder = './path/to/your/datasets/folder' ds = DatasetDownloader(destination_folder, dataset=\"isol\") ds.download() To download the continuous version, just replace dataset=\"isol\" with dataset=\"cont\" Advanced Usage To give you more control about what is downloaded, the DatasetDownloader class propose several parameters : destination : Path to the folder where the dataset will be downloaded. (str) dataset : Type of dataset to download. Must be either isol or cont (str) exclude : A list of the data to exclude from the download. The possible values are video (to skip the download of the videos), landmarks (to skip the download of the mediapipe skeleton information) and annotations (to skip the download of gloss annotation for the continuous dataset). (list) src : The source url of the dataset. By default, the dataset is downloaded from our server. (str) warning_message : By default, the script display a warning message to the user. If you want to disable this message, set this parameter to False . (bool)","title":"Download Datasets"},{"location":"download/#download-datasets","text":"To ease the download of the datasets, we provide a python script that will download the datasets for you. The script is desined to download the dataset in an incremental way. Thus, no worries if you stop the download midway. The script will resume the download where it left off. It is also able to update the dataset if new videos or feature are added.","title":"Download Datasets"},{"location":"download/#basic-usage","text":"Here is a simple snippet of code to download the isolated version of the dataset : from lsfb_dataset.utils.download.dataset_downloader import DatasetDownloader destination_folder = './path/to/your/datasets/folder' ds = DatasetDownloader(destination_folder, dataset=\"isol\") ds.download() To download the continuous version, just replace dataset=\"isol\" with dataset=\"cont\"","title":"Basic Usage"},{"location":"download/#advanced-usage","text":"To give you more control about what is downloaded, the DatasetDownloader class propose several parameters : destination : Path to the folder where the dataset will be downloaded. (str) dataset : Type of dataset to download. Must be either isol or cont (str) exclude : A list of the data to exclude from the download. The possible values are video (to skip the download of the videos), landmarks (to skip the download of the mediapipe skeleton information) and annotations (to skip the download of gloss annotation for the continuous dataset). (list) src : The source url of the dataset. By default, the dataset is downloaded from our server. (str) warning_message : By default, the script display a warning message to the user. If you want to disable this message, set this parameter to False . (bool)","title":"Advanced Usage"},{"location":"lsfb_cont/","text":"LSFB-CONT LSFB CONT is a dataset for continuous sign language recognition. It is made of videos of deaf people talking together. Each video of the dataset are annotated with the gloss of each sign for each hands. Some video are also directly translated to french. The following section will provide more details about the dataset, its annotation and the various pre-computed features of the video. In order to download the LSFB CONT dataset, pleas contact me at the address jerome.fink[at]unamur.be Videos The videos of the LSFB CONT dataset are all recorded in 720x576px resolution with 50 FPS. The duration of the video is variable (between 30 seconds and 30 minutes). The signers were asked to accomplish several tasks such as summurizing a video, describing a picture or tell a childhood story. The videos.csv file of the dataset contains the list of all the available video along with several metadata : filename : the name of the video file (e.g. CLSFBI0103_S001_B.mp4 ) category : the category of the video (e.g. CLSFB - 01 ok ) filepath : the relative path of the video (eg videos\\CLSFB - 01 ok\\CLSFBI0103A_S001_B.mp4 ) frames : the number of frames in the video (ex: 25274 ) right_hand_annotations : the relative path of the right hand annotations left_hand_annotations : the relative path of the left hand annotations face_positions : the relative path of the face landmarks hands_positions : the relative path of the hand landmarks pose_positions : the relative path of the skeleton landmarks holistic_features : the relative path of the holistic landmarks holistic_features_cleaned : the relative path of the cleaned holistic landmarks The actual content of all these files are presented in the following section. Left and Right hands Annotations The LSFB video are annotated using gloss. Glosses are unique labels associated to each sign. The annotations CSV contains the following columns : start : Starting time of the gloss (in milliseconds) end : Ending time of the gloss (in milliseconds) word : The label of the gloss The annotations CSV files were created based on the original annotations created by the LSFB-LAB . Those annotation are available on demande and use the ELAN file format. Along with the gloss annotation, the ELAN file also contains an alligned french translation. However, frenche translation is still a work in progress and will be available in its own CSV file when ready. Extracted landmarks From each frame of each video a set of landmarks is extracted. These landmarks relate to the main speaker in the video. The different sets of landmarks extracted: The face The pose (skeleton) The hands These very precise data are then aggregated into another set of landmarks, the holistic landmarks. Holistics landmarks are also available in a cleaned version where an interpolation and a smoothing phase have been applied. Face landmarks There are 468 facial landmarks (numbered from 0 to 467). The corresponding CSV file therefore has 2x468 (for X and Y respectively) or 936 columns. Let FACE_0_X, FACE_0_Y, FACE_1_X, FACE_1_Y, ... , FACE_467_X, FACE_467_Y, . Skeleton landmarks The pose landmarks are 33 in number (numbered 0 to 32). The corresponding CSV file therefore has 2x33 (for X and Y respectively) or 66 columns. In order to identify the part of the body concerned, please refer to the image below. The columns are in the same order as in the image and are in capitals. So: NOSE_X, NOSE_Y, LEFT_EYE_INNER_X, LEFT_EYE_INNER_Y, ..., RIGHT_FOOT_INDEX_X, RIGHT_FOOT_INDEX_Y . Hand landmarks The hand landmarks are primarily for the right hand, and then the left hand. Each hand has 21 landmarks (numbered from 0 to 20). Each landmark consists of an X position and a Y position. This makes a total of (2 hands) x (21 landmarks) x (2 dimensions), or 84 columns. The column names are in upper case and are ordered first by hand, then by the name of the landmark in the image below, and finally by X and Y. This gives: RIGHT_WRIST_X, RIGHT_WRIST_Y, ..., RIGHT_PINKY_TIP_X, RIGHT_PINKY_TIP_Y, LEFT_WRIST_X, LEFT_WRIST_Y, ..., LEFT_PINKY_TIP_X, LEFT_PINKY_TIP_Y Holistic landmarks There are 5 holistic landmarks: the face (FACE): A point located at the average postion of the face landmarks the right hand (RIGHT_HAND): A point located at the average of the right hand landmarks left hand (LEFT_HAND): A point located at the average of the left hand landmarks right shoulder (RIGHT_SHOULDER): A point located at the right shoulder marker the left shoulder (LEFT_SHOULDER): A point located at the left shoulder marker These landmarks are separated into two dimensions (X and Y). So there are 10 columns in the CSV file: FACE_X , FACE_Y , RIGHT_HAND_X , RIGHT_HAND_Y , LEFT_HAND_X , LEFT_HAND_Y , RIGHT_SHOULDER_X , RIGHT_SHOULDER_Y , LEFT_SHOULDER_X , LEFT_SHOULDER_Y","title":"LSFB Cont"},{"location":"lsfb_cont/#lsfb-cont","text":"LSFB CONT is a dataset for continuous sign language recognition. It is made of videos of deaf people talking together. Each video of the dataset are annotated with the gloss of each sign for each hands. Some video are also directly translated to french. The following section will provide more details about the dataset, its annotation and the various pre-computed features of the video. In order to download the LSFB CONT dataset, pleas contact me at the address jerome.fink[at]unamur.be","title":"LSFB-CONT"},{"location":"lsfb_cont/#videos","text":"The videos of the LSFB CONT dataset are all recorded in 720x576px resolution with 50 FPS. The duration of the video is variable (between 30 seconds and 30 minutes). The signers were asked to accomplish several tasks such as summurizing a video, describing a picture or tell a childhood story. The videos.csv file of the dataset contains the list of all the available video along with several metadata : filename : the name of the video file (e.g. CLSFBI0103_S001_B.mp4 ) category : the category of the video (e.g. CLSFB - 01 ok ) filepath : the relative path of the video (eg videos\\CLSFB - 01 ok\\CLSFBI0103A_S001_B.mp4 ) frames : the number of frames in the video (ex: 25274 ) right_hand_annotations : the relative path of the right hand annotations left_hand_annotations : the relative path of the left hand annotations face_positions : the relative path of the face landmarks hands_positions : the relative path of the hand landmarks pose_positions : the relative path of the skeleton landmarks holistic_features : the relative path of the holistic landmarks holistic_features_cleaned : the relative path of the cleaned holistic landmarks The actual content of all these files are presented in the following section.","title":"Videos"},{"location":"lsfb_cont/#left-and-right-hands-annotations","text":"The LSFB video are annotated using gloss. Glosses are unique labels associated to each sign. The annotations CSV contains the following columns : start : Starting time of the gloss (in milliseconds) end : Ending time of the gloss (in milliseconds) word : The label of the gloss The annotations CSV files were created based on the original annotations created by the LSFB-LAB . Those annotation are available on demande and use the ELAN file format. Along with the gloss annotation, the ELAN file also contains an alligned french translation. However, frenche translation is still a work in progress and will be available in its own CSV file when ready.","title":"Left and Right hands Annotations"},{"location":"lsfb_cont/#extracted-landmarks","text":"From each frame of each video a set of landmarks is extracted. These landmarks relate to the main speaker in the video. The different sets of landmarks extracted: The face The pose (skeleton) The hands These very precise data are then aggregated into another set of landmarks, the holistic landmarks. Holistics landmarks are also available in a cleaned version where an interpolation and a smoothing phase have been applied.","title":"Extracted landmarks"},{"location":"lsfb_cont/#face-landmarks","text":"There are 468 facial landmarks (numbered from 0 to 467). The corresponding CSV file therefore has 2x468 (for X and Y respectively) or 936 columns. Let FACE_0_X, FACE_0_Y, FACE_1_X, FACE_1_Y, ... , FACE_467_X, FACE_467_Y, .","title":"Face landmarks"},{"location":"lsfb_cont/#skeleton-landmarks","text":"The pose landmarks are 33 in number (numbered 0 to 32). The corresponding CSV file therefore has 2x33 (for X and Y respectively) or 66 columns. In order to identify the part of the body concerned, please refer to the image below. The columns are in the same order as in the image and are in capitals. So: NOSE_X, NOSE_Y, LEFT_EYE_INNER_X, LEFT_EYE_INNER_Y, ..., RIGHT_FOOT_INDEX_X, RIGHT_FOOT_INDEX_Y .","title":"Skeleton landmarks"},{"location":"lsfb_cont/#hand-landmarks","text":"The hand landmarks are primarily for the right hand, and then the left hand. Each hand has 21 landmarks (numbered from 0 to 20). Each landmark consists of an X position and a Y position. This makes a total of (2 hands) x (21 landmarks) x (2 dimensions), or 84 columns. The column names are in upper case and are ordered first by hand, then by the name of the landmark in the image below, and finally by X and Y. This gives: RIGHT_WRIST_X, RIGHT_WRIST_Y, ..., RIGHT_PINKY_TIP_X, RIGHT_PINKY_TIP_Y, LEFT_WRIST_X, LEFT_WRIST_Y, ..., LEFT_PINKY_TIP_X, LEFT_PINKY_TIP_Y","title":"Hand landmarks"},{"location":"lsfb_cont/#holistic-landmarks","text":"There are 5 holistic landmarks: the face (FACE): A point located at the average postion of the face landmarks the right hand (RIGHT_HAND): A point located at the average of the right hand landmarks left hand (LEFT_HAND): A point located at the average of the left hand landmarks right shoulder (RIGHT_SHOULDER): A point located at the right shoulder marker the left shoulder (LEFT_SHOULDER): A point located at the left shoulder marker These landmarks are separated into two dimensions (X and Y). So there are 10 columns in the CSV file: FACE_X , FACE_Y , RIGHT_HAND_X , RIGHT_HAND_Y , LEFT_HAND_X , LEFT_HAND_Y , RIGHT_SHOULDER_X , RIGHT_SHOULDER_Y , LEFT_SHOULDER_X , LEFT_SHOULDER_Y","title":"Holistic landmarks"},{"location":"lsfb_isol/","text":"LSFB-ISOL The LSFB-ISOL dataset pictures isolated signs extracted from the LSFB-CONT dataset. The dataset propose 635 unique gloss with at least 40 occurrences per gloss for a total of 54.551 videos. You can download the dataset on the official website . Loading the dataset Once you've donwloaded the dataset, you can use this companion library to easily load it into a dataframe with the following code : from lsfb_dataset.datasets.lsfb_isol.lsfb_isol_dataset import LsfbIsolDataset dataset_dir = \"./lsfb_isol\" dataset = LsfbIsolDataset(dataset_dir) This class creates a pytorch dataset . The constructor of the class takes the following arguments: root : The path to the root directory of the dataset. str transforms : A list of transformation to apply on the input data (see pytorch transform ). Optional[List[Callable]] features : List of the features you want to load. By default only the video frame are loaded. The possible value are : Hand landmarks, Face landmarks, Pose landmarks and video. The landmarks are provided by mediapipe Optional[List[str]] labels : Allows you to provide a custom label mapping between the string label of the gloss and a numerical label. If not provided the mapping is automatically created. Optional[Dict[str, int]] max_frames : The maximum number of frames to load for each video. (default=50) Optional[int] The dataset could be iterated and return a tuple containing the numeric label of the considered gloss and a dictionnary containing a key for each loaded feature and a numpy array containing the data for this feature. DataLoader (Pytorch) The dataset could then be used with a pytorch dataloader to load the data in a batch for the training.","title":"LSFB Isol"},{"location":"lsfb_isol/#lsfb-isol","text":"The LSFB-ISOL dataset pictures isolated signs extracted from the LSFB-CONT dataset. The dataset propose 635 unique gloss with at least 40 occurrences per gloss for a total of 54.551 videos. You can download the dataset on the official website .","title":"LSFB-ISOL"},{"location":"lsfb_isol/#loading-the-dataset","text":"Once you've donwloaded the dataset, you can use this companion library to easily load it into a dataframe with the following code : from lsfb_dataset.datasets.lsfb_isol.lsfb_isol_dataset import LsfbIsolDataset dataset_dir = \"./lsfb_isol\" dataset = LsfbIsolDataset(dataset_dir) This class creates a pytorch dataset . The constructor of the class takes the following arguments: root : The path to the root directory of the dataset. str transforms : A list of transformation to apply on the input data (see pytorch transform ). Optional[List[Callable]] features : List of the features you want to load. By default only the video frame are loaded. The possible value are : Hand landmarks, Face landmarks, Pose landmarks and video. The landmarks are provided by mediapipe Optional[List[str]] labels : Allows you to provide a custom label mapping between the string label of the gloss and a numerical label. If not provided the mapping is automatically created. Optional[Dict[str, int]] max_frames : The maximum number of frames to load for each video. (default=50) Optional[int] The dataset could be iterated and return a tuple containing the numeric label of the considered gloss and a dictionnary containing a key for each loaded feature and a numpy array containing the data for this feature.","title":"Loading the dataset"},{"location":"lsfb_isol/#dataloader-pytorch","text":"The dataset could then be used with a pytorch dataloader to load the data in a batch for the training.","title":"DataLoader (Pytorch)"},{"location":"transforms/","text":"Transforms The transforms class are inspired from the TorchVision transforms workflow. Unfortunately, torchvision does not (yet) provides transforms for video. To help you to easily build your own pre-processing or data augmentation workflow we created several extension of torchvision transforms for video. How to Use Transforms The transfoms must be imported and could be chain as you like : from torchvision import transforms from lsfb_dataset.transforms.video_transforms import ( ChangeVideoShape, ResizeVideo, RandomCropVideo, CenterCropVideo, I3DPixelsValue, RandomTrimVideo, TrimVideo, PadVideo, ) from lsfb_dataset.datasets.lsfb_dataset import LsfbDataset composed_train = transforms.Compose( [ RandomTrimVideo(nbr_frames), PadVideo(nbr_frames), ResizeVideo(270, interpolation=\"linear\"), RandomCropVideo((224, 224)), I3DPixelsValue(), ChangeVideoShape(\"CTHW\"), ] ) train_dataset = LsfbDataset(train_split, transforms=composed_train, max_frame = 100) Available Transforms I3DPixelsValue By default, the dataloader normalize the pixel value between 0 and 1. This transformation will change that to normalize the pixels value between -1 and 1 like in the I3D paper. ChangeVideoShape Expect to receive tha video in the shape (Time, Height, Width, Channels) which is the default format of cv2 or PIL and change this shape to either channel first CTHW (Channels, Time, Height, Width) or time first TCHW format. ResizeVideo Resize a video in shape (T, H, W, C) to the desired size. RandomCropVideo Crop randomly a video in shape (T, H, W, C) to the desired size. CenterCropVideo Crop a video in shape (T, H, W, C) at its center. TrimVideo Reduce the length of the video to the desired number of frames. RandomTrimVideo Trim randomly the video to the desired length. This could be use as a type of data augmentation PadVideo Pad the video to the desired length. The padding could eather be made by looping the video or by adding zero frame at the end.","title":"Transforms"},{"location":"transforms/#transforms","text":"The transforms class are inspired from the TorchVision transforms workflow. Unfortunately, torchvision does not (yet) provides transforms for video. To help you to easily build your own pre-processing or data augmentation workflow we created several extension of torchvision transforms for video.","title":"Transforms"},{"location":"transforms/#how-to-use-transforms","text":"The transfoms must be imported and could be chain as you like : from torchvision import transforms from lsfb_dataset.transforms.video_transforms import ( ChangeVideoShape, ResizeVideo, RandomCropVideo, CenterCropVideo, I3DPixelsValue, RandomTrimVideo, TrimVideo, PadVideo, ) from lsfb_dataset.datasets.lsfb_dataset import LsfbDataset composed_train = transforms.Compose( [ RandomTrimVideo(nbr_frames), PadVideo(nbr_frames), ResizeVideo(270, interpolation=\"linear\"), RandomCropVideo((224, 224)), I3DPixelsValue(), ChangeVideoShape(\"CTHW\"), ] ) train_dataset = LsfbDataset(train_split, transforms=composed_train, max_frame = 100)","title":"How to Use Transforms"},{"location":"transforms/#available-transforms","text":"","title":"Available Transforms"},{"location":"transforms/#i3dpixelsvalue","text":"By default, the dataloader normalize the pixel value between 0 and 1. This transformation will change that to normalize the pixels value between -1 and 1 like in the I3D paper.","title":"I3DPixelsValue"},{"location":"transforms/#changevideoshape","text":"Expect to receive tha video in the shape (Time, Height, Width, Channels) which is the default format of cv2 or PIL and change this shape to either channel first CTHW (Channels, Time, Height, Width) or time first TCHW format.","title":"ChangeVideoShape"},{"location":"transforms/#resizevideo","text":"Resize a video in shape (T, H, W, C) to the desired size.","title":"ResizeVideo"},{"location":"transforms/#randomcropvideo","text":"Crop randomly a video in shape (T, H, W, C) to the desired size.","title":"RandomCropVideo"},{"location":"transforms/#centercropvideo","text":"Crop a video in shape (T, H, W, C) at its center.","title":"CenterCropVideo"},{"location":"transforms/#trimvideo","text":"Reduce the length of the video to the desired number of frames.","title":"TrimVideo"},{"location":"transforms/#randomtrimvideo","text":"Trim randomly the video to the desired length. This could be use as a type of data augmentation","title":"RandomTrimVideo"},{"location":"transforms/#padvideo","text":"Pad the video to the desired length. The padding could eather be made by looping the video or by adding zero frame at the end.","title":"PadVideo"},{"location":"visualisation/","text":"Visualisation The visualisation module allows you to visualise the video present in the dataset along with all the metadata associated with them (landmarks, labels). The main class of this module is the VideoPlayer class : from lsfb_dataset.visualisation.video import VideoPlayer video_path = \"./path/to/video.mp4\" player = VideoPlayer(video_path) player.play() The VideoPlayer accept the path ( str ) to the video as an argument. The play function is then called to display the video selected using OpenCV. The class also provides methods to attach metadata to the video : from lsfb_dataset.visualisation.video import VideoPlayer # Creating the VideoPlayer for the video player = VideoPlayer(vid_path) # Attaching the csv file to the video player.attach_holistic_features(hollistic_features_path) player.attach_annotations(right_hand_path, hand='right') player.attach_annotations(left_hand_path, hand='left') # Telling the player that those information should be displayed player.show_landmarks(True) player.show_boxes(True) player.show_duration(True) player.play() In this more complex example, we attach the csv file containing the corresponding metadata to the video and we tell the player which additional information should be displayed.","title":"Visualisation"},{"location":"visualisation/#visualisation","text":"The visualisation module allows you to visualise the video present in the dataset along with all the metadata associated with them (landmarks, labels). The main class of this module is the VideoPlayer class : from lsfb_dataset.visualisation.video import VideoPlayer video_path = \"./path/to/video.mp4\" player = VideoPlayer(video_path) player.play() The VideoPlayer accept the path ( str ) to the video as an argument. The play function is then called to display the video selected using OpenCV. The class also provides methods to attach metadata to the video : from lsfb_dataset.visualisation.video import VideoPlayer # Creating the VideoPlayer for the video player = VideoPlayer(vid_path) # Attaching the csv file to the video player.attach_holistic_features(hollistic_features_path) player.attach_annotations(right_hand_path, hand='right') player.attach_annotations(left_hand_path, hand='left') # Telling the player that those information should be displayed player.show_landmarks(True) player.show_boxes(True) player.show_duration(True) player.play() In this more complex example, we attach the csv file containing the corresponding metadata to the video and we tell the player which additional information should be displayed.","title":"Visualisation"}]}