{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"LSFB Dataset LSFB Dataset is a companion library for the French Belgian Sign Language (LSFB) dataset released by the University of Namur. The library provides a set of tools helping to load the dataset in python data structures or to visualize the data. This library reduce drastically the time you will spend on data loading and preprocessing allowing you to focus on your research. Content The dataset is available in two versions : * LSFB Isol : depicting isolated signs * LSFB cont : depicting continuous signs","title":"LSFB Dataset"},{"location":"#lsfb-dataset","text":"LSFB Dataset is a companion library for the French Belgian Sign Language (LSFB) dataset released by the University of Namur. The library provides a set of tools helping to load the dataset in python data structures or to visualize the data. This library reduce drastically the time you will spend on data loading and preprocessing allowing you to focus on your research.","title":"LSFB Dataset"},{"location":"#content","text":"The dataset is available in two versions : * LSFB Isol : depicting isolated signs * LSFB cont : depicting continuous signs","title":"Content"},{"location":"lsfb_cont/","text":"LSFB-CONT LSFB CONT is a dataset for continuous sign language recognition. It is made of videos of deaf people talking together. Each video of the dataset are annotated with the gloss of each sign for each hands. Some video are also directly translated to french. The following section will provide more details about the dataset, its annotation and the various pre-computed features of the video. In order to download the LSFB CONT dataset, pleas contact me at the address jerome.fink[at]unamur.be Videos The videos of the LSFB CONT dataset are all recorded in 720x576px resolution with 50 FPS. The duration of the video is variable (between 30 seconds and 30 minutes). The signers were asked to accomplish several tasks such as summurizing a video, describing a picture or tell a childhood story. The videos.csv file of the dataset contains the list of all the available video along with several metadata : filename : the name of the video file (e.g. CLSFBI0103_S001_B.mp4 ) category : the category of the video (e.g. CLSFB - 01 ok ) filepath : the relative path of the video (eg videos\\CLSFB - 01 ok\\CLSFBI0103A_S001_B.mp4 ) frames : the number of frames in the video (ex: 25274 ) right_hand_annotations : the relative path of the right hand annotations left_hand_annotations : the relative path of the left hand annotations face_positions : the relative path of the face landmarks hands_positions : the relative path of the hand landmarks pose_positions : the relative path of the skeleton landmarks holistic_features : the relative path of the holistic landmarks holistic_features_cleaned : the relative path of the cleaned holistic landmarks The actual content of all these files are presented in the following section. Left and Right hands Annotations The LSFB video are annotated using gloss. Glosses are unique labels associated to each sign. The annotations CSV contains the following columns : start : Starting time of the gloss (in milliseconds) end : Ending time of the gloss (in milliseconds) word : The label of the gloss The annotations CSV files were created based on the original annotations created by the LSFB-LAB . Those annotation are available on demande and use the ELAN file format. Along with the gloss annotation, the ELAN file also contains an alligned french translation. However, frenche translation is still a work in progress and will be available in its own CSV file when ready. Extracted landmarks From each frame of each video a set of landmarks is extracted. These landmarks relate to the main speaker in the video. The different sets of landmarks extracted: The face The pose (skeleton) The hands These very precise data are then aggregated into another set of landmarks, the holistic landmarks. Holistics landmarks are also available in a cleaned version where an interpolation and a smoothing phase have been applied. Face landmarks There are 468 facial landmarks (numbered from 0 to 467). The corresponding CSV file therefore has 2x468 (for X and Y respectively) or 936 columns. Let FACE_0_X, FACE_0_Y, FACE_1_X, FACE_1_Y, ... , FACE_467_X, FACE_467_Y, . Skeleton landmarks The pose landmarks are 33 in number (numbered 0 to 32). The corresponding CSV file therefore has 2x33 (for X and Y respectively) or 66 columns. In order to identify the part of the body concerned, please refer to the image below. The columns are in the same order as in the image and are in capitals. So: NOSE_X, NOSE_Y, LEFT_EYE_INNER_X, LEFT_EYE_INNER_Y, ..., RIGHT_FOOT_INDEX_X, RIGHT_FOOT_INDEX_Y . Hand landmarks The hand landmarks are primarily for the right hand, and then the left hand. Each hand has 21 landmarks (numbered from 0 to 20). Each landmark consists of an X position and a Y position. This makes a total of (2 hands) x (21 landmarks) x (2 dimensions), or 84 columns. The column names are in upper case and are ordered first by hand, then by the name of the landmark in the image below, and finally by X and Y. This gives: RIGHT_WRIST_X, RIGHT_WRIST_Y, ..., RIGHT_PINKY_TIP_X, RIGHT_PINKY_TIP_Y, LEFT_WRIST_X, LEFT_WRIST_Y, ..., LEFT_PINKY_TIP_X, LEFT_PINKY_TIP_Y Holistic landmarks There are 5 holistic landmarks: the face (FACE): A point located at the average postion of the face landmarks the right hand (RIGHT_HAND): A point located at the average of the right hand landmarks left hand (LEFT_HAND): A point located at the average of the left hand landmarks right shoulder (RIGHT_SHOULDER): A point located at the right shoulder marker the left shoulder (LEFT_SHOULDER): A point located at the left shoulder marker These landmarks are separated into two dimensions (X and Y). So there are 10 columns in the CSV file: FACE_X , FACE_Y , RIGHT_HAND_X , RIGHT_HAND_Y , LEFT_HAND_X , LEFT_HAND_Y , RIGHT_SHOULDER_X , RIGHT_SHOULDER_Y , LEFT_SHOULDER_X , LEFT_SHOULDER_Y","title":"LSFB-CONT"},{"location":"lsfb_cont/#lsfb-cont","text":"LSFB CONT is a dataset for continuous sign language recognition. It is made of videos of deaf people talking together. Each video of the dataset are annotated with the gloss of each sign for each hands. Some video are also directly translated to french. The following section will provide more details about the dataset, its annotation and the various pre-computed features of the video. In order to download the LSFB CONT dataset, pleas contact me at the address jerome.fink[at]unamur.be","title":"LSFB-CONT"},{"location":"lsfb_cont/#videos","text":"The videos of the LSFB CONT dataset are all recorded in 720x576px resolution with 50 FPS. The duration of the video is variable (between 30 seconds and 30 minutes). The signers were asked to accomplish several tasks such as summurizing a video, describing a picture or tell a childhood story. The videos.csv file of the dataset contains the list of all the available video along with several metadata : filename : the name of the video file (e.g. CLSFBI0103_S001_B.mp4 ) category : the category of the video (e.g. CLSFB - 01 ok ) filepath : the relative path of the video (eg videos\\CLSFB - 01 ok\\CLSFBI0103A_S001_B.mp4 ) frames : the number of frames in the video (ex: 25274 ) right_hand_annotations : the relative path of the right hand annotations left_hand_annotations : the relative path of the left hand annotations face_positions : the relative path of the face landmarks hands_positions : the relative path of the hand landmarks pose_positions : the relative path of the skeleton landmarks holistic_features : the relative path of the holistic landmarks holistic_features_cleaned : the relative path of the cleaned holistic landmarks The actual content of all these files are presented in the following section.","title":"Videos"},{"location":"lsfb_cont/#left-and-right-hands-annotations","text":"The LSFB video are annotated using gloss. Glosses are unique labels associated to each sign. The annotations CSV contains the following columns : start : Starting time of the gloss (in milliseconds) end : Ending time of the gloss (in milliseconds) word : The label of the gloss The annotations CSV files were created based on the original annotations created by the LSFB-LAB . Those annotation are available on demande and use the ELAN file format. Along with the gloss annotation, the ELAN file also contains an alligned french translation. However, frenche translation is still a work in progress and will be available in its own CSV file when ready.","title":"Left and Right hands Annotations"},{"location":"lsfb_cont/#extracted-landmarks","text":"From each frame of each video a set of landmarks is extracted. These landmarks relate to the main speaker in the video. The different sets of landmarks extracted: The face The pose (skeleton) The hands These very precise data are then aggregated into another set of landmarks, the holistic landmarks. Holistics landmarks are also available in a cleaned version where an interpolation and a smoothing phase have been applied.","title":"Extracted landmarks"},{"location":"lsfb_cont/#face-landmarks","text":"There are 468 facial landmarks (numbered from 0 to 467). The corresponding CSV file therefore has 2x468 (for X and Y respectively) or 936 columns. Let FACE_0_X, FACE_0_Y, FACE_1_X, FACE_1_Y, ... , FACE_467_X, FACE_467_Y, .","title":"Face landmarks"},{"location":"lsfb_cont/#skeleton-landmarks","text":"The pose landmarks are 33 in number (numbered 0 to 32). The corresponding CSV file therefore has 2x33 (for X and Y respectively) or 66 columns. In order to identify the part of the body concerned, please refer to the image below. The columns are in the same order as in the image and are in capitals. So: NOSE_X, NOSE_Y, LEFT_EYE_INNER_X, LEFT_EYE_INNER_Y, ..., RIGHT_FOOT_INDEX_X, RIGHT_FOOT_INDEX_Y .","title":"Skeleton landmarks"},{"location":"lsfb_cont/#hand-landmarks","text":"The hand landmarks are primarily for the right hand, and then the left hand. Each hand has 21 landmarks (numbered from 0 to 20). Each landmark consists of an X position and a Y position. This makes a total of (2 hands) x (21 landmarks) x (2 dimensions), or 84 columns. The column names are in upper case and are ordered first by hand, then by the name of the landmark in the image below, and finally by X and Y. This gives: RIGHT_WRIST_X, RIGHT_WRIST_Y, ..., RIGHT_PINKY_TIP_X, RIGHT_PINKY_TIP_Y, LEFT_WRIST_X, LEFT_WRIST_Y, ..., LEFT_PINKY_TIP_X, LEFT_PINKY_TIP_Y","title":"Hand landmarks"},{"location":"lsfb_cont/#holistic-landmarks","text":"There are 5 holistic landmarks: the face (FACE): A point located at the average postion of the face landmarks the right hand (RIGHT_HAND): A point located at the average of the right hand landmarks left hand (LEFT_HAND): A point located at the average of the left hand landmarks right shoulder (RIGHT_SHOULDER): A point located at the right shoulder marker the left shoulder (LEFT_SHOULDER): A point located at the left shoulder marker These landmarks are separated into two dimensions (X and Y). So there are 10 columns in the CSV file: FACE_X , FACE_Y , RIGHT_HAND_X , RIGHT_HAND_Y , LEFT_HAND_X , LEFT_HAND_Y , RIGHT_SHOULDER_X , RIGHT_SHOULDER_Y , LEFT_SHOULDER_X , LEFT_SHOULDER_Y","title":"Holistic landmarks"},{"location":"lsfb_isol/","text":"LSFB-ISOL The LSFB-ISOL dataset pictures isolated signs extracted from the LSFB-CONT dataset. The dataset propose 395 unique gloss with at least 40 occurrences per gloss for a total of 47.551 videos. You can download the dataset on the official website . Loading the dataset Once you donwloaded the dataset, you can use this companion library to easily load it into a dataframe with the following code : from lsfb_dataset.utils.dataset_loader import load_lsfb_dataset df = load_lsfb_dataset(\"./dataset/path\") train_split = df[df[\"subset\"] == \"train\"] test_split = df[df[\"subset\"] == \"test\"] The loaded dataframe contains 4 columns : label : the gloss of the sign (str) label_nbr : Unique number associated with to the gloss (int) subset : The dataset is already split into train and test subsets. This column indicates which subset the video belongs to (str) path : The path to the video (str) The dataframe could then be used to create a Pytorch Dataset . DataLoader (Pytorch) To dynamically load datasets too big to fit in memory, Pytorch provides a Dataset class that can be used to load the dataset in a streaming fashion. This library provide a custom dataloader for the LSFB-ISOL dataset. The lsfb_dataset.datasets.lsfb_dataset.LsfbIsolDataset class propose a constructor with the following parameters : df : The dataframe containing the dataset obtained with the load_lsfb_dataset function label_padding : Required when sequence_label is True. The value is a string indicating if the label should be looped or not. The value can be either \"loop\" or \"no_loop\". If the labels are not looped, a special padding label is created to fill the sequence. sequence_label : Boolean value indicating if the labels should be returned as a sequence instead of a single value for the whole video sequence. transforms : A series of transformations to apply to the video. max_frame : The maximum number of frames to extract from the video. labels : Dictionnary containing a label mapping between each gloss and a unique id. If none the mapping is created from the dataframe. The following code snippets show how to load the dataset and create a LsfbIsolDataset object: from lsfb_dataset.utils.dataset_loader import load_lsfb_dataset from lsfb_dataset.datasets.lsfb_dataset import LsfbDataset df = load_lsfb_dataset(\"./dataset/path\") train_split = df[df[\"subset\"] == \"train\"] train_dataset = LsfbDataset(train_split, max_frame = 100)","title":"LSFB-ISOL"},{"location":"lsfb_isol/#lsfb-isol","text":"The LSFB-ISOL dataset pictures isolated signs extracted from the LSFB-CONT dataset. The dataset propose 395 unique gloss with at least 40 occurrences per gloss for a total of 47.551 videos. You can download the dataset on the official website .","title":"LSFB-ISOL"},{"location":"lsfb_isol/#loading-the-dataset","text":"Once you donwloaded the dataset, you can use this companion library to easily load it into a dataframe with the following code : from lsfb_dataset.utils.dataset_loader import load_lsfb_dataset df = load_lsfb_dataset(\"./dataset/path\") train_split = df[df[\"subset\"] == \"train\"] test_split = df[df[\"subset\"] == \"test\"] The loaded dataframe contains 4 columns : label : the gloss of the sign (str) label_nbr : Unique number associated with to the gloss (int) subset : The dataset is already split into train and test subsets. This column indicates which subset the video belongs to (str) path : The path to the video (str) The dataframe could then be used to create a Pytorch Dataset .","title":"Loading the dataset"},{"location":"lsfb_isol/#dataloader-pytorch","text":"To dynamically load datasets too big to fit in memory, Pytorch provides a Dataset class that can be used to load the dataset in a streaming fashion. This library provide a custom dataloader for the LSFB-ISOL dataset. The lsfb_dataset.datasets.lsfb_dataset.LsfbIsolDataset class propose a constructor with the following parameters : df : The dataframe containing the dataset obtained with the load_lsfb_dataset function label_padding : Required when sequence_label is True. The value is a string indicating if the label should be looped or not. The value can be either \"loop\" or \"no_loop\". If the labels are not looped, a special padding label is created to fill the sequence. sequence_label : Boolean value indicating if the labels should be returned as a sequence instead of a single value for the whole video sequence. transforms : A series of transformations to apply to the video. max_frame : The maximum number of frames to extract from the video. labels : Dictionnary containing a label mapping between each gloss and a unique id. If none the mapping is created from the dataframe. The following code snippets show how to load the dataset and create a LsfbIsolDataset object: from lsfb_dataset.utils.dataset_loader import load_lsfb_dataset from lsfb_dataset.datasets.lsfb_dataset import LsfbDataset df = load_lsfb_dataset(\"./dataset/path\") train_split = df[df[\"subset\"] == \"train\"] train_dataset = LsfbDataset(train_split, max_frame = 100)","title":"DataLoader (Pytorch)"}]}